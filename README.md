# Resume Parser - Portfolio Project

A robust resume parsing system that extracts and structures candidate information from PDF resumes. This project demonstrates proficiency in text processing, data engineering, and building scalable data pipelines.

## ğŸ¯ Project Overview

This application automates the extraction of key information from resume PDFs including:
- **Personal Information**: Name, Email, Phone
- **Education**: Degree and Institution
- **Skills**: Technical and Professional Skills
- **Experience**: Job titles and companies (extensible)

Designed for recruiter dashboards, ATS systems, or data analysis pipelines.

## âœ¨ Features

- **PDF Text Extraction**: Robust PDF parsing using PyMuPDF (fitz)
- **Text Preprocessing**: Intelligent normalization and cleaning
- **Pattern Matching**: Regex-based field extraction with validation
- **Batch Processing**: Process multiple resumes efficiently
- **Error Handling**: Graceful handling of malformed PDFs
- **Logging**: Comprehensive logging for debugging and monitoring
- **Structured Output**: CSV export for further analysis
- **Type Safety**: Full type hints for better code quality

## ğŸ› ï¸ Tech Stack

- **Language**: Python 3.8+
- **Core Libraries**: 
  - PyMuPDF (fitz) - PDF processing
  - Pandas - Data manipulation
  - Regex - Pattern matching
- **Testing**: pytest (included in requirements)
- **Code Quality**: Type hints, docstrings, logging

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8 or higher
- pip or conda

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/AdityaM24/ResumeIQ.git
cd ResumeIQ
```

2. **Create a virtual environment** (recommended)
```bash
# Using venv
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Or using conda
conda create -n resume-parser python=3.8
conda activate resume-parser
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

## ğŸš€ Usage

### Basic Usage - Process Resumes in Batch

```bash
python run.py
```

This will:
1. Read all PDFs from `data/raw_resumes/`
2. Extract and parse candidate information
3. Save structured data to `data/processed_output/parsed_resumes.csv`

### Programmatic Usage

```python
from src.pipeline import process_resume

# Process a single resume
result = process_resume("path/to/resume.pdf")
print(result)
# Output: {'Name': '...', 'Email': '...', 'Education': '...', 'Skills': [...], 'File': '...'}
```

### Directory Structure

```
resume-parser/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                     # Package configuration
â”œâ”€â”€ run.py                       # Main entry point
â”œâ”€â”€ config.py                    # Configuration constants
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extract_text.py         # PDF text extraction
â”‚   â”œâ”€â”€ preprocess.py           # Text normalization
â”‚   â”œâ”€â”€ parser.py               # Information extraction
â”‚   â””â”€â”€ pipeline.py             # Orchestration
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_extract_text.py
â”‚   â”œâ”€â”€ test_parser.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb          # Data exploration & visualization
â””â”€â”€ data/
    â”œâ”€â”€ raw_resumes/            # Input PDFs
    â””â”€â”€ processed_output/       # Output CSVs
```

## ğŸ§ª Testing

Run the test suite:

```bash
pytest tests/ -v
```

Run with coverage:

```bash
pytest tests/ --cov=src --cov-report=html
```

## ğŸ“Š Analysis

Explore the parsed data using Jupyter notebook:

```bash
jupyter notebook notebooks/analysis.ipynb
```

The notebook includes:
- Skill frequency analysis
- Education distribution
- Data quality metrics

## ğŸ”§ Configuration

Edit `config.py` to customize:
- Input/output directories
- Skill keywords database
- Education degree types
- Logging levels

## ğŸ“ Code Quality

- **Type Hints**: All functions have type annotations
- **Docstrings**: Google-style docstrings for all modules
- **Logging**: Debug, info, and error logging throughout
- **Error Handling**: Try-except blocks with meaningful messages
- **Testing**: Unit tests for all core functionality

## ğŸš¦ Development

### Running in Debug Mode

```bash
python run.py --debug
```

### Extending the Parser

To add new fields (e.g., phone number, experience years):

1. Add extraction function in `src/parser.py`:
```python
def extract_phone(text: str) -> Optional[str]:
    """Extract phone number from resume text."""
    match = re.search(r'\b\d{10}\b|\+\d{1,3}[-.\s]?\d{10}\b', text)
    return match.group(0) if match else None
```

2. Update `parse_resume()` to include the new field:
```python
def parse_resume(text: str) -> dict:
    return {
        "Name": extract_name(text),
        "Email": extract_email(text),
        "Phone": extract_phone(text),  # Add this
        ...
    }
```

3. Add tests in `tests/test_parser.py`

## ğŸ“ˆ Performance Considerations

- **Current**: Processes ~100 resumes/minute on standard hardware
- **Scalability**: Can be extended with async processing for larger batches
- **Memory**: Optimized for processing large PDFs

## ğŸ› Known Limitations

- Name extraction uses heuristic approach (first two words)
- Skill detection based on predefined keywords
- Education extraction limited to common degree types
- May struggle with non-standard resume formats

## ğŸ”® Future Enhancements

- [ ] Machine learning-based NER for better accuracy
- [ ] Support for other document formats (DOCX, XLSX)
- [ ] API endpoint for resume upload and processing
- [ ] GUI for batch processing
- [ ] Database integration (MongoDB/PostgreSQL)
- [ ] Docker containerization
- [ ] More sophisticated name/location extraction

## ğŸ“š Learning Resources

This project demonstrates:
- PDF processing and text extraction
- Regular expressions for pattern matching
- Data pipeline design
- Error handling and logging
- Unit testing
- Type hints in Python
- Pandas for data manipulation

## ğŸ¤ Contributing

To contribute:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -m 'Add improvement'`)
4. Push to branch (`git push origin feature/improvement`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’¼ Author

**Aditya Mahale**
- GitHub: [@AdityaM24](https://github.com/AdityaM24)
- Email: adityamahale76@gmail.com
- Project: [ResumeIQ](https://github.com/AdityaM24/ResumeIQ)

## ğŸ“§ Contact

For questions or feedback, please:
- Open an [issue on GitHub](https://github.com/AdityaM24/ResumeIQ/issues)
- Send an email to adityamahale76@gmail.com

---

**Last Updated**: January 2026
**Version**: 1.0.0
**Repository**: https://github.com/AdityaM24/ResumeIQ
